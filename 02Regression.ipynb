{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "055f09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e8f17",
   "metadata": {},
   "source": [
    "### Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e867727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e05ae01e70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = tf.constant([-7.0, -4.0, -1.0,  2.0,  5.0,  8.0, 11.0, 14.0])\n",
    "y = tf.constant([ 3.0,  6.0,  9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16cb9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=bool, numpy=array([ True,  True,  True,  True,  True,  True,  True,  True])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y==X+10 #the relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513a91c",
   "metadata": {},
   "source": [
    "### Regression input shapes and output shapes\n",
    "One of the most important concepts when working with neural networks are the input and output shapes.\n",
    "\n",
    "The input shape is the shape of your data that goes into the model.\n",
    "\n",
    "The output shape is the shape of your data you want to come out of your model.\n",
    "\n",
    "These will differ depending on the problem you're working on.\n",
    "\n",
    "Neural networks accept numbers and output numbers. These numbers are typically represented as tensors (or arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3aad912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'rooms', b'garage', b'bethroom'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1000000], dtype=int32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example input and output shapes of a housing price regression model\n",
    "infos=tf.constant([\"rooms\",\"garage\",\"bethroom\"])#shape=3\n",
    "price=tf.constant([1000000])#shape=1\n",
    "infos,price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea5cb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([8]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape , X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20657c00",
   "metadata": {},
   "source": [
    "The whole dataset has shape (8,) â†’ 8 numbers.\n",
    "\n",
    "But a single example from it has shape () â†’ just one number.\n",
    "\n",
    "ğŸ“Œ Why this matters:\n",
    "When you build a neural network, you must tell it the shape of a single example, not the whole dataset. Thatâ€™s called the input shape of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f3b1db",
   "metadata": {},
   "source": [
    "## Your first model : \n",
    "In TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n",
    "\n",
    "Creating a model - piece together the layers of a neural network yourself (using the Functional or Sequential API) or import a previously built model (known as transfer learning).\n",
    "Compiling a model - defining how a models performance should be measured (loss/metrics) as well as defining how it should improve (optimizer).\n",
    "Fitting a model - letting the model try to find patterns in the data (how does X get to y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486fc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835ms/step - loss: 10.7307 - mae: 10.7307\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 10.5982 - mae: 10.5982\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 10.4657 - mae: 10.4657\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 10.3332 - mae: 10.3332\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 10.2007 - mae: 10.2007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e05b0d7850>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)]\n",
    ")\n",
    "model.compile(loss=tf.keras.losses.mae ,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"]\n",
    "              )\n",
    "model.fit(tf.expand_dims(X,axis=1),y,epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e504e",
   "metadata": {},
   "source": [
    "Sequential: This creates a linear stack of layers (one after another)\n",
    "Dense(1): This is a fully connected layer with just 1 neuron\n",
    "Dense layers connect every input to every output\n",
    "With 1 neuron, this model will output a single number (like predicting a price, temperature, etc.)\n",
    "\n",
    "What is a Dense Layer?\n",
    "Think of a Dense layer like a connection hub where every input connects to every output.\n",
    "Input Features:    Dense Layer (1 neuron):    Output:\n",
    "[house_size]  â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚\n",
    "[bedrooms]    â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€ [neuron] â”€â”€â”€â”€â”€â”€ [predicted_price]\n",
    "                    â”‚\n",
    "[location]    â”€â”€â”€â”€â”€â”€â”˜\n",
    "How it Works:\n",
    "\n",
    "Every input connects to the neuron: All 3 features connect to that 1 neuron\n",
    "The neuron does math: It multiplies each input by a weight and adds them up\n",
    "neuron_output = (house_size Ã— weight1) + (bedrooms Ã— weight2) + (location Ã— weight3) + bias\n",
    "\n",
    "Produces 1 output: Since there's only 1 neuron, you get 1 prediction\n",
    "\n",
    "Why \"Fully Connected\"?\n",
    "\n",
    "Fully connected = every input touches every neuron\n",
    "If you had 2 neurons, each input would connect to BOTH neurons\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "loss: How the model measures how \"wrong\" it is\n",
    "\n",
    "MAE (Mean Absolute Error): Takes the average of absolute differences between predictions and actual values\n",
    "Example: if actual=10 and prediction=7, error = |10-7| = 3\n",
    "\n",
    "optimizer: How the model learns and improves\n",
    "\n",
    "SGD (Stochastic Gradient Descent): A basic learning algorithm that adjusts the model's weights to reduce the loss\n",
    "\n",
    "metrics: What to track during training (here, also MAE for monitoring)\n",
    "\n",
    "--------------------------------------------------------------------------------------------------\n",
    "\n",
    "tf.expand_dims(X, axis=-1): This reshapes your input data\n",
    "\n",
    "If X was shape (100,) â†’ becomes (100, 1)\n",
    "Neural networks expect 2D input: (samples, features)\n",
    "The -1 means \"add dimension at the end\"\n",
    "\n",
    "epochs=5: The model will see the entire dataset 5 times\n",
    "\n",
    "Each epoch = one complete pass through all your training data\n",
    "\n",
    "This is a simple linear regression model that learns to map input X to output y with a straight line relationship!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8f9e612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try the model\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26493184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15.509592]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr=model.predict(tf.expand_dims([16],axis=1))\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead073e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.710293]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15!?, thats wrong, lets step back and see the last value of loss (10.2007)\n",
    "pr+10.2007 #25.71 = almost 26 /its not always representive thought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadaac30",
   "metadata": {},
   "source": [
    "### Improving our model \n",
    "To improve our model, we alter almost every part of the 3 steps we went through before.\n",
    "\n",
    "Creating a model - here you might want to add more layers, increase the number of hidden units (also called neurons) within each layer, change the activation functions of each layer.\n",
    "Compiling a model - you might want to choose optimization function or perhaps change the learning rate of the optimization function.\n",
    "Fitting a model - perhaps you could fit a model for more epochs (leave it training for longer) or on more data (give the model more examples to learn from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33eebd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 12.4688 - mae: 12.4688\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 11.8292 - mae: 11.8292\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 11.1837 - mae: 11.1837\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 10.5291 - mae: 10.5291\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 9.8627 - mae: 9.8627\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 9.1822 - mae: 9.1822\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 8.4849 - mae: 8.4849\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 7.7681 - mae: 7.7681\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 7.0291 - mae: 7.0291\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 6.8361 - mae: 6.8361\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 7.2047 - mae: 7.2047\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 7.4804 - mae: 7.4804\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 7.8151 - mae: 7.8151\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 7.8869 - mae: 7.8869\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 7.7615 - mae: 7.7615\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 7.4909 - mae: 7.4909\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 7.1254 - mae: 7.1254\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 6.8666 - mae: 6.8666\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 6.5939 - mae: 6.5939\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 6.3114 - mae: 6.3114\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 6.1892 - mae: 6.1892\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 6.1485 - mae: 6.1485\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 6.2780 - mae: 6.2780\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 6.3605 - mae: 6.3605\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 6.3442 - mae: 6.3442\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 6.2417 - mae: 6.2417\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 6.0621 - mae: 6.0621\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 5.8119 - mae: 5.8119\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 5.6201 - mae: 5.6201\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5.5132 - mae: 5.5132\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 5.4296 - mae: 5.4296\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5.4363 - mae: 5.4363\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 5.4003 - mae: 5.4003\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 5.3245 - mae: 5.3245\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 5.2120 - mae: 5.2120\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5.0657 - mae: 5.0657\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 4.8885 - mae: 4.8885\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4.7408 - mae: 4.7408\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.6468 - mae: 4.6468\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.5448 - mae: 4.5448\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.4347 - mae: 4.4347\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.3886 - mae: 4.3886\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 4.2313 - mae: 4.2313\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 4.0262 - mae: 4.0262\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 3.8652 - mae: 3.8652\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 3.6964 - mae: 3.6964\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.5990 - mae: 3.5990\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 3.4756 - mae: 3.4756\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.2983 - mae: 3.2983\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 3.0697 - mae: 3.0697\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 2.8345 - mae: 2.8345\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.6526 - mae: 2.6526\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.4979 - mae: 2.4979\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.2538 - mae: 2.2538\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.0001 - mae: 2.0001\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 1.8555 - mae: 1.8555\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 1.6701 - mae: 1.6701\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.4185 - mae: 1.4185\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.0503 - mae: 1.0503\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.8985 - mae: 0.8985\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7225 - mae: 0.7225\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3672 - mae: 0.3672\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1548 - mae: 0.1548\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4167 - mae: 0.4167\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4773 - mae: 0.4773\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.6686 - mae: 0.6686\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.6749 - mae: 0.6749\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7170 - mae: 0.7170\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.6737 - mae: 0.6737\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.6403 - mae: 0.6403\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.6383 - mae: 0.6383\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.4274 - mae: 0.4274\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3570 - mae: 0.3570\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.2276 - mae: 0.2276\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0635 - mae: 0.0635\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.1613 - mae: 0.1613\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.2481 - mae: 0.2481\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.2614 - mae: 0.2614\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.2719 - mae: 0.2719\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.2899 - mae: 0.2899\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.1924 - mae: 0.1924\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.2380 - mae: 0.2380\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1987 - mae: 0.1987\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.1665 - mae: 0.1665\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.2339 - mae: 0.2339\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1364 - mae: 0.1364\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.2479 - mae: 0.2479\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1165 - mae: 0.1165\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.2543 - mae: 0.2543\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.2428 - mae: 0.2428\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1293 - mae: 0.1293\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.2035 - mae: 0.2035\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0786 - mae: 0.0786\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3279 - mae: 0.3279\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3266 - mae: 0.3266\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0874 - mae: 0.0874\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.4095 - mae: 0.4095\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.5091 - mae: 0.5091\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.3148 - mae: 0.3148\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1401 - mae: 0.1401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e05ca238b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if we can make another to improve our model\n",
    "\n",
    "# 1. Create the model (this time with an extra hidden layer with 50 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(50, activation=None),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=\"mae\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), #Remember that potantially Lr is the most important hyper parameter on all of your neural network\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X,axis=1),y,epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23379246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.6626]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr=model.predict(tf.expand_dims([16],axis=1))\n",
    "pr #its now better!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecaee7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
